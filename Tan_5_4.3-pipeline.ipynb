{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b0bca9-5577-4ea9-9b39-dc22caec158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fe9757-2bdb-47be-8869-36a088523891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/27 17:06:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/27 17:06:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=SparkConf())\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579d1e8-d03f-4e64-8730-b23f9c43ff91",
   "metadata": {},
   "source": [
    "# Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f83dfd-8ba8-4fea-b87e-e79f526e5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+\n",
      "| x1|    x2| x3| x4| y1| y2|\n",
      "+---+------+---+---+---+---+\n",
      "|  a| apple|  1|2.4|  1|yes|\n",
      "|  a|orange|  1|2.5|  0| no|\n",
      "|  b|orange|  2|3.5|  1| no|\n",
      "|  b|orange|  2|1.4|  0|yes|\n",
      "|  b| peach|  2|2.1|  0|yes|\n",
      "|  c| peach|  4|1.5|  1|yes|\n",
      "+---+------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf = pd.DataFrame({\n",
    "    'x1': ['a','a','b','b', 'b', 'c'],\n",
    "    'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
    "    'x3': [1, 1, 2, 2, 2, 4],\n",
    "    'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
    "    'y1': [1, 0, 1, 0, 0, 1],\n",
    "    'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
    "    })\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2462c0-9226-4789-9a85-f073b0aa2bb3",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "Pipeline is a sequence of stages which consists of **Estimators** and/or **Transformers**.\n",
    "**Estimator** has **fit** method and **Transformer** has **transform** method. Therefore, we can say,\n",
    "**a pipeline is a sequence of fit and transform methods.**\n",
    "When it is a **fit** method, it applies to the input data and turns into a **transform** method. \n",
    "Then the **transform** method applies to the **fitted** data and output **transformed** data.\n",
    "**The transformed data output from previous stage has to be an acceptable input to the next stage's fit/tranform method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beed40ba-0bbc-4a80-8512-847f94f7d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9deb50b-f6e8-4654-8c58-89556bdaedb5",
   "metadata": {},
   "source": [
    "# Example\n",
    "We are going to use pipeline to StringIndex columns x1, x2, y1, and y2.\n",
    "Then we OneHotEncode the resulting StringIndexed columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4909b-8c1c-42c6-9a06-bf18184695c8",
   "metadata": {},
   "source": [
    "**StringIndexer** is used to convert catgorical string columns into numerical indices\n",
    "inputcol is the column to be indexed, outputCol is the column that will store the indexed values(prefixed with idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6ef999-a71b-4a64-bc1f-2baf908563f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_910f073d56e0,\n",
       " StringIndexer_506df0d5cf9f,\n",
       " StringIndexer_ca05a2ab046c,\n",
       " StringIndexer_5797c224d37e]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of StringIndexer stages for each column in the pipeline.\n",
    "stringindex_stages = [StringIndexer(inputCol=c, outputCol='idx_' + c) for c in ['x1', 'x2', 'y1', 'y2' ]]\n",
    "stringindex_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15189a50-148b-4ab0-a424-14e4536c98f6",
   "metadata": {},
   "source": [
    "**OneHotEncoder** creates a binary vector for each category in the indexed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110a9cfb-2883-47e2-9c91-0d7e8f5cbfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OneHotEncoder_b010c734ce37,\n",
       " OneHotEncoder_b6766cd86ef4,\n",
       " OneHotEncoder_f39a10fa09f2,\n",
       " OneHotEncoder_85123b739ca9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform one-hot encoding on the indexed columns(generated by StringIndexer)\n",
    "onehotencode_stages = [OneHotEncoder(inputCol='idx_' + c, outputCol='ohe_' + c) for c in ['x1', 'x2', 'y1', 'y2' ]]\n",
    "onehotencode_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9c04f-768d-42ac-b656-7303614050cd",
   "metadata": {},
   "source": [
    "Note that the outputCol label in StringIndex stages is the same as the **inputCol label** in the OneHotEncode stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebacba-b6d2-4d23-b413-4e63f18531fb",
   "metadata": {},
   "source": [
    "# Elements in the stage list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bc2b6c-2200-491c-bd20-301a9a760a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.StringIndexer,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder,\n",
       " pyspark.ml.feature.OneHotEncoder]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the StringIndexer and OneHotEncoder stages into one list\n",
    "all_stages = stringindex_stages + onehotencode_stages\n",
    "[type(x) for x in all_stages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bd7e9-e1bc-4ee6-9915-2a40b9b035d7",
   "metadata": {},
   "source": [
    "In the above list, **pyspark.ml.feature.StringIndexer** is an **Estimator**(has a fit method) and \n",
    "**pyspark.ml.feature.OneHotEncoder** is a **transformer**(has a transform method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab2eb7-0410-4f61-99c9-1e6db9b09be6",
   "metadata": {},
   "source": [
    "# Build and run pipeline\n",
    "build a pipeline that uses the stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf819137-0947-4405-ae4b-a0fb06277268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
      "| x1|    x2| x3| x4| y1| y2|idx_x1|idx_x2|idx_y1|idx_y2|       ohe_x1|       ohe_x2|       ohe_y1|       ohe_y2|\n",
      "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
      "|  a| apple|  1|2.4|  1|yes|   1.0|   2.0|   1.0|   0.0|(2,[1],[1.0])|    (2,[],[])|    (1,[],[])|(1,[0],[1.0])|\n",
      "|  a|orange|  1|2.5|  0| no|   1.0|   0.0|   0.0|   1.0|(2,[1],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|    (1,[],[])|\n",
      "|  b|orange|  2|3.5|  1| no|   0.0|   0.0|   1.0|   1.0|(2,[0],[1.0])|(2,[0],[1.0])|    (1,[],[])|    (1,[],[])|\n",
      "|  b|orange|  2|1.4|  0|yes|   0.0|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  b| peach|  2|2.1|  0|yes|   0.0|   1.0|   0.0|   0.0|(2,[0],[1.0])|(2,[1],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|  c| peach|  4|1.5|  1|yes|   2.0|   1.0|   1.0|   0.0|    (2,[],[])|(2,[1],[1.0])|    (1,[],[])|(1,[0],[1.0])|\n",
      "+---+------+---+---+---+---+------+------+------+------+-------------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Pipeline(stages=all_stages).fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff236b-aae3-47a6-940b-89c41cae0c45",
   "metadata": {},
   "source": [
    "# Reorder pipeline stages\n",
    "In the example above, out strategy is to StringIndex all four columns and then OneHotEncode them.\n",
    "Since each OneHotEncode stage only depends on the output of their corresponding **StringIndex** stage,\n",
    "our stages list could be **[stringindexer on x1, onehotencoder on x1, stringindexer on x2, onehotencoder on x2, stringindexer on y1, onehotencoder on y1, stringindexer on y2, onehotencoder on y2]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee95bb4-fde9-4c80-87cd-da362569a672",
   "metadata": {},
   "source": [
    "## Old stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6275c9-4565-4927-92c5-df36c74f85c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_910f073d56e0,\n",
       " StringIndexer_506df0d5cf9f,\n",
       " StringIndexer_ca05a2ab046c,\n",
       " StringIndexer_5797c224d37e,\n",
       " OneHotEncoder_b010c734ce37,\n",
       " OneHotEncoder_b6766cd86ef4,\n",
       " OneHotEncoder_f39a10fa09f2,\n",
       " OneHotEncoder_85123b739ca9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63644dd-28f0-487b-89dc-305525fdd273",
   "metadata": {},
   "source": [
    "## New stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a638f7e-5539-4021-ab5d-7ee7c3064a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_910f073d56e0,\n",
       " OneHotEncoder_b010c734ce37,\n",
       " StringIndexer_506df0d5cf9f,\n",
       " OneHotEncoder_b6766cd86ef4,\n",
       " StringIndexer_ca05a2ab046c,\n",
       " OneHotEncoder_f39a10fa09f2,\n",
       " StringIndexer_5797c224d37e,\n",
       " OneHotEncoder_85123b739ca9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reorder the stages in a more logical order to make the encoding after indexing\n",
    "new_all_stages = [all_stages[x] for x in [0,4,1,5,2,6,3,7]]\n",
    "new_all_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c47b42-90bf-4684-9df4-f7e4a0081083",
   "metadata": {},
   "source": [
    "## Build and run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bcc2862-18bf-4d7d-90d9-5a10f1aaaead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
      "| x1|    x2| x3| x4| y1| y2|idx_x1|       ohe_x1|idx_x2|       ohe_x2|idx_y1|       ohe_y1|idx_y2|       ohe_y2|\n",
      "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
      "|  a| apple|  1|2.4|  1|yes|   1.0|(2,[1],[1.0])|   2.0|    (2,[],[])|   1.0|    (1,[],[])|   0.0|(1,[0],[1.0])|\n",
      "|  a|orange|  1|2.5|  0| no|   1.0|(2,[1],[1.0])|   0.0|(2,[0],[1.0])|   0.0|(1,[0],[1.0])|   1.0|    (1,[],[])|\n",
      "|  b|orange|  2|3.5|  1| no|   0.0|(2,[0],[1.0])|   0.0|(2,[0],[1.0])|   1.0|    (1,[],[])|   1.0|    (1,[],[])|\n",
      "|  b|orange|  2|1.4|  0|yes|   0.0|(2,[0],[1.0])|   0.0|(2,[0],[1.0])|   0.0|(1,[0],[1.0])|   0.0|(1,[0],[1.0])|\n",
      "|  b| peach|  2|2.1|  0|yes|   0.0|(2,[0],[1.0])|   1.0|(2,[1],[1.0])|   0.0|(1,[0],[1.0])|   0.0|(1,[0],[1.0])|\n",
      "|  c| peach|  4|1.5|  1|yes|   2.0|    (2,[],[])|   1.0|(2,[1],[1.0])|   1.0|    (1,[],[])|   0.0|(1,[0],[1.0])|\n",
      "+---+------+---+---+---+---+------+-------------+------+-------------+------+-------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new pipeline with the reordered stages and run\n",
    "# pipeline helps in chaining multiple stages (transformations) for streamlined data processing.\n",
    "Pipeline(stages=new_all_stages).fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d7912-14c8-492e-8575-34fc2e28fb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
