{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebdf4e51-3482-4de6-a2d5-8011fe50caac",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce1e49-e6a9-4ff4-8577-22283c3cd8a4",
   "metadata": {},
   "source": [
    "Use multinomial logistic regression to predict multiple classes based on features provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3360fea0-36fb-40b9-895a-92c223200e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d60225-1267-4377-a57a-9827e10e7c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/03 18:30:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=SparkConf())\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9771dc-0017-4188-a2b3-517dc2e2c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 18:30:33 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "data = spark.read.format(\"libsvm\").load(\"data/SparkData/sample_multiclass_classification_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c55bbb2-ced7-4640-ab9c-11419c9aaaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  2.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfb7508-952b-4e99-92e5-4b3309f0d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  0.0|(4,[0,1,2,3],[0.1...|\n",
      "|  1.0|(4,[0,2,3],[-0.83...|\n",
      "|  2.0|(4,[0,1,2,3],[-1....|\n",
      "|  2.0|(4,[0,1,2,3],[-1....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  0.0|(4,[0,2,3],[0.611...|\n",
      "|  0.0|(4,[0,1,2,3],[0.2...|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  2.0|(4,[0,1,2,3],[-0....|\n",
      "|  2.0|(4,[0,1,2,3],[-0....|\n",
      "|  2.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,2,3],[-0.94...|\n",
      "|  2.0|(4,[0,1,2,3],[-0....|\n",
      "|  0.0|(4,[0,1,2,3],[0.1...|\n",
      "|  2.0|(4,[0,1,2,3],[-0....|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f802603a-31bd-45ac-b3a1-07f4daeeb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecde8b2-e045-4cce-9143-819db2c31929",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, \\\n",
    "                        featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03956478-a492-44e9-86da-1ed12524728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 18:30:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0689549-7ea3-4c05-8515-afbed5a49de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(4,[0,1,2,3],[-0....|[0.17671197056610...|[0.41386611807366...|       0.0|\n",
      "|  0.0|(4,[0,1,2,3],[0.0...|[0.12642328579967...|[0.39292057646508...|       2.0|\n",
      "|  0.0|(4,[0,1,2,3],[0.0...|[0.25214529944908...|[0.44635661507787...|       0.0|\n",
      "|  0.0|(4,[0,1,2,3],[0.1...|[0.12642328579967...|[0.40898887447851...|       2.0|\n",
      "|  0.0|(4,[0,1,2,3],[0.2...|[0.12642328579967...|[0.40710013779628...|       2.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = model.transform(test_data)\n",
    "# select example rows to display\n",
    "predictions.show(5)\n",
    "# predictions.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c67493-d2b8-4fae-9e8a-992159453f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "|label|rawPrediction                                                  |probability                                                 |prediction|\n",
      "+-----+---------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "|2.0  |[0.050989956916697915,-0.36966871193287,0.15870503324587906]   |[0.3609659300637143,0.237015350356587,0.4020187195796988]   |2.0       |\n",
      "|2.0  |[-0.07473235846602755,-0.10868145817303719,0.15870503324587906]|[0.30964023440344984,0.2993046615709015,0.39105510402564864]|2.0       |\n",
      "|2.0  |[0.02584540332015816,-0.3120415482160539,0.15870503324587906]  |[0.3502178507432775,0.24980195901951904,0.39998019023720355]|2.0       |\n",
      "|2.0  |[0.12642328579967008,-0.542548199148243,0.15870503324587906]   |[0.39292057646508016,0.20126772983728808,0.4058116936976317]|2.0       |\n",
      "|2.0  |[0.02584540332015816,-0.39347822941933586,0.15870503324587906] |[0.35719630302705957,0.2348534884568156,0.4079502085161247] |2.0       |\n",
      "+-----+---------------------------------------------------------------+------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('label', 'rawPrediction', 'probability', 'prediction').filter('label = 2.0').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "860383a1-0b84-4cf2-8ac6-adad5225b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: 3 X 4 CSRMatrix\n",
      "(0,3) 0.3017\n",
      "(1,2) -0.8008\n",
      "(1,3) -0.3658\n",
      "Intercepts: [0.0007009704169446199,-0.15940600366282368,0.15870503324587906]\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients and intercept for multinomial logistic regresssion\n",
    "print(\"Coefficients: {}\".format(model.coefficientMatrix))\n",
    "print(\"Intercepts: {}\".format(model.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da7f8ac-b4e6-47ad-8441-d7d2709988cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba812d7-52cc-4dee-8581-45e3bfde0a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n",
      "label 0:0.0\n",
      "label 1:0.011904761904761904\n",
      "label 2:0.20253164556962025\n"
     ]
    }
   ],
   "source": [
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i in range(len(trainingSummary.falsePositiveRateByLabel)):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.falsePositiveRateByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e33a03b3-f36f-480c-aaca-b5e6c7cc3a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0: 0.5897435897435898\n",
      "label 1: 1.0\n",
      "label 2: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i in range(len(trainingSummary.truePositiveRateByLabel)):\n",
    "    print(\"label {}: {}\".format(i, trainingSummary.truePositiveRateByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c88e9f-3294-4d46-a749-4e977ff788b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 0.975609756097561\n",
      "label 2: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by label:\")\n",
    "for i in range(len(trainingSummary.precisionByLabel)):\n",
    "    print(\"label {}: {}\".format(i, trainingSummary.precisionByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b63c8e5d-1512-477a-942d-b1f31ef0f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall by label:\n",
      "label 0: 0.5897435897435898\n",
      "label 1: 1.0\n",
      "label 2: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall by label:\")\n",
    "for i in range(len(trainingSummary.recallByLabel)):\n",
    "    print(\"label {}: {}\".format(i, trainingSummary.recallByLabel[i]))\n",
    "# recall need improvement for label2(class 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda1c5c8-c294-4d17-875e-bcce1b1cb23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure by label:\n",
      "label 0: 0.7419354838709677\n",
      "label 1: 0.9876543209876543\n",
      "label 2: 0.838095238095238\n"
     ]
    }
   ],
   "source": [
    "print(\"F-measure by label:\")\n",
    "for i in range(len(trainingSummary.fMeasureByLabel())):\n",
    "    print(\"label {}: {}\".format(i, trainingSummary.fMeasureByLabel()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d03bd76e-bb79-4686-b2c9-23d14a39d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = trainingSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e36f3a-ec8f-4bfd-aa6f-83d60c4da469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8629032258064516\n",
      "FPR: 0.07733963328083378\n",
      "TPR: 0.8629032258064517\n",
      "F-measure: 0.8560963098770938\n",
      "Precision: 0.8953579858379228\n",
      "Recall: 0.8629032258064517\n"
     ]
    }
   ],
   "source": [
    "# False positive rate is the percent the model incorrectly predicts the class\n",
    "# True positive rate is the percent the model correctly predicts the class\n",
    "# Precision is the percent of the correctly prediction out of all times\n",
    "# Recall is the percent that the model correctly identifies out of all the actual class instances)\n",
    "# F-measure is the harmonic mean of precision and recall, balancing both metrics.\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: {0}\\nFPR: {1}\\nTPR: {2}\\nF-measure: {3}\\nPrecision: {4}\\nRecall: {5}\".format \\\n",
    "      (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f46d995a-f5cf-4921-82d0-574cc56675a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.192308\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy)) # test error means the percent the model misclassified of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53a807-b9d5-4577-9c3a-fe559550c3f9",
   "metadata": {},
   "source": [
    "## There are 3 lines determines 3 classes (3 predictive values), hence, 3 slopes and 3 intercepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b6ba96-aff4-4160-b98d-37fdd52ea411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(3, 4, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8008, 0.0, 0.3017, -0.3658, 0.0], False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.coefficientMatrix represents the weights for each feature for each of the 3 classes\n",
    "# positive coefficient increases the likelihood of predicting the class while negative coefficient decreases it.\n",
    "model.coefficientMatrix.toDense()\n",
    "# for class 1, feature 2 has a coefficent of -0.7575, feature 3 has a coefficient of -0.292.\n",
    "# for class 2, feature 3 has a coefficent of 0.3665."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "583e5415-0782-4217-aa49-1ab15fa68c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0007, -0.1594, 0.1587])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercepts for class 0, 1, and 2\n",
    "model.interceptVector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
