{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db3f8f5-827d-4791-ac26-976783ae04c5",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f118e20-8e4a-4a57-9f85-2406e81f29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27188bec-fd5e-4af2-b09a-c853bb37e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home/hadoop/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home/hadoop/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# one time run on the PC; need to run it everytime on colab and databrick notebooks\n",
    "!pip install -U --quiet scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79cdcaad-1036-499f-a469-19809622384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46e0f22c-ed98-45ad-8990-5d6d3c75a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 20:40:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=SparkConf())\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad45cf2-9a1c-40dd-850d-e24fff829fc0",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machine with pyspark\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c1351f7-d4d1-4513-8551-11d0836b3a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "|age|        job|marital|education|default|balance|housing|loan| contact|duration|campaign|pdays|previous|  y|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular|      79|       1|   -1|       0| no|\n",
      "| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular|     220|       1|  339|       4| no|\n",
      "| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular|     185|       1|  330|       1| no|\n",
      "| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|     199|       4|   -1|       0| no|\n",
      "| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|     226|       1|   -1|       0| no|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/SparkData/bank.csv', header=True, inferSchema=True, sep=\";\")\n",
    "df.drop('day', 'month', 'poutcome').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31bd6b36-8282-4dbd-8fa6-9e15d768ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bd685-91d6-456c-a3a4-559593479597",
   "metadata": {},
   "source": [
    "## Deal with categorical data and Convert the data to dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de84eead-36ec-4592-916c-b4b04a38382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "num_cols = ['balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "labelCol = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5e257-0d6c-4c7a-9d4a-722059e36540",
   "metadata": {},
   "source": [
    "### Process categorical columns\n",
    "The following code does three things with pipeline:<br>\n",
    "* StringIndexer all categorical columns<br>\n",
    "* OneHotEncoder all categorical index columns<br>\n",
    "* VectorAssembler all feature columns into one vector column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a18f-f785-4d4b-b768-486254553e44",
   "metadata": {},
   "source": [
    "Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "774d5efe-8bf2-4faf-9a4c-d699b1ebaf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7491180-31f1-4105-9b0e-3302f99a92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using StringIndexer to convert categorical columns into numeric indices\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f91fc2a9-b1a5-4d94-938c-8ab6e8a641d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver indexed categorical columns into sparse vectors\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), \\\n",
    "                           outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e909792b-189e-4201-b151-8b08f179a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combin numerical and encoded categorical columns into a single feature vector for training\n",
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() \\\n",
    "                                        for encoder in encoders] + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d983354-3661-4081-b832-ab8fe90f1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                 |label|\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|(29,[8,11,15,16,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1787.0,79.0,1.0,-1.0])                |no   |\n",
      "|(29,[4,11,13,16,17,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4789.0,220.0,1.0,339.0,4.0])       |no   |\n",
      "|(29,[0,12,14,16,17,18,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1350.0,185.0,1.0,330.0,1.0])|no   |\n",
      "|(29,[0,11,14,16,17,20,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1476.0,199.0,4.0,-1.0])               |no   |\n",
      "|(29,[1,11,13,16,17,18,20,21,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,226.0,1.0,-1.0])                  |no   |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "model = pipeline.fit(df)\n",
    "data = model.transform(df)\n",
    "data = data.withColumn('label', col(labelCol))\n",
    "data = data.select('features', 'label')\n",
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c3b6-92bf-4187-9d97-49831ce60e06",
   "metadata": {},
   "source": [
    "### We need to deal with label, which is string, yes or no, need to make them numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda7b22-41ba-4519-86bc-fc70063f806f",
   "metadata": {},
   "source": [
    "Build StringIndexer stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a85ccdd1-2c6d-4fcc-80fc-de56354eecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label', outputCol='indexedLabel').fit(data)\n",
    "data=labelIndexer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3b34919-d751-4b94-84e9-1de78731026a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|label|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(29,[8,11,15,16,1...|   no|         0.0|\n",
      "|(29,[4,11,13,16,1...|   no|         0.0|\n",
      "|(29,[0,12,14,16,1...|   no|         0.0|\n",
      "|(29,[0,11,14,16,1...|   no|         0.0|\n",
      "|(29,[1,11,13,16,1...|   no|         0.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7f0dcaf-2a64-46a5-ac2d-2af239c42fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# use VectorIndexer to automatically identify categorical features, and index them\n",
    "# set maxCategories so features with >4 distinct values are treated as continuous\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "858c0e3a-c8fa-495c-81c3-2166bf646628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+--------------------+\n",
      "|            features|label|indexedLabel|     indexedFeatures|\n",
      "+--------------------+-----+------------+--------------------+\n",
      "|(29,[8,11,15,16,1...|   no|         0.0|(29,[8,11,15,16,1...|\n",
      "|(29,[4,11,13,16,1...|   no|         0.0|(29,[4,11,13,16,1...|\n",
      "|(29,[0,12,14,16,1...|   no|         0.0|(29,[0,12,14,16,1...|\n",
      "|(29,[0,11,14,16,1...|   no|         0.0|(29,[0,11,14,16,1...|\n",
      "|(29,[1,11,13,16,1...|   no|         0.0|(29,[1,11,13,16,1...|\n",
      "+--------------------+-----+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=featureIndexer.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e8824-9e5e-49ae-9547-a8e3ca5c4a6e",
   "metadata": {},
   "source": [
    "### Split the data to training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99bdcd5f-b4a7-4b4e-b3a8-51cfe4dddf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                        |label|indexedLabel|indexedFeatures                                                                                 |\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-588.0,81.0,4.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-588.0,81.0,4.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,466.0,164.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,466.0,164.0,1.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,644.0,54.0,2.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,644.0,54.0,2.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,857.0,238.0,6.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,857.0,238.0,6.0,-1.0])|\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                        |label|indexedLabel|indexedFeatures                                                                                 |\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-105.0,60.0,2.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-105.0,60.0,2.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,725.0,266.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,725.0,266.0,1.0,-1.0])|\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test sets (40% held out for testing)\n",
    "(train_data, test_data) = data.randomSplit([0.6, 0.4])\n",
    "train_data.show(5, False)\n",
    "test_data.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bec0ed-8477-420e-ad8f-4021fe5d84a2",
   "metadata": {},
   "source": [
    "### Build cross-validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22f65cd5-6643-4a98-9227-87c6c153e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC model\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(featuresCol=\"indexedFeatures\", labelCol=\"indexedLabel\", maxIter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeada159-4e86-4982-aa9c-e4745ea4a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "from pyspark.ml.feature import IndexToString\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c728775-c8d2-4ed1-a71b-077ea86e6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[lsvc, labelConverter])\n",
    "# train model, this also runs the indexers\n",
    "lsvcModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51768c-b25f-4ca6-95ca-8dbb6be98031",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "758d944b-ce93-4d00-988c-b5c4b2d96dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+--------------------+--------------------+----------+--------------+\n",
      "|            features|label|indexedLabel|     indexedFeatures|       rawPrediction|prediction|predictedLabel|\n",
      "+--------------------+-----+------------+--------------------+--------------------+----------+--------------+\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.0650679352406,...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.05898663021228...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[0.96445812005862...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.05340940108253...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.03711121871714...|       0.0|            no|\n",
      "+--------------------+-----+------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = lsvcModel.transform(test_data)\n",
    "# select example rows to display\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29015e52-485c-4dfe-881c-ba6fa4ab0f77",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0c4a613-6818-4d2e-9099-b4b4f3d3e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8961407491486947\n",
      "Test error = 0.103859\n"
     ]
    }
   ],
   "source": [
    "# use MulticlassClassificationEvaluator to evaluate the model's accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea74e4c-acbe-474e-917c-1eb536b331d9",
   "metadata": {},
   "source": [
    "### Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffa703cf-e0df-4cd3-9c55-d468e20f22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions.select(\"prediction\").collect()\n",
    "y_orig = predictions.select(\"indexedLabel\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1349d680-a538-48b6-a745-2b87484ee952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1548   18]\n",
      " [ 165   31]]\n"
     ]
    }
   ],
   "source": [
    "# generate confusion matrix to evalutate the classification performance\n",
    "cm = confusion_matrix(y_orig, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b9618-6f06-40b1-9d7f-4d5b7b36b4d1",
   "metadata": {},
   "source": [
    "### Here is the slope of the hyper-plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a883f52-51c2-4691-9789-7627ada0eee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.063, -0.059, -0.0497, -0.054, -0.0668, -0.0573, -0.0441, -0.0567, -0.0624, -0.0606, -0.0451, -0.0212, -0.0148, 0.0052, 0.0175, 0.0016, -0.0308, -0.0042, 0.0235, -0.0082, -0.0388, -2.0486, -1.9968, -2.0, 0.0, 0.0001, 0.0001, -0.0002, -0.0021])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.stages[0].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f596dc-6084-4ca0-bd6f-67899574fafa",
   "metadata": {},
   "source": [
    "### Here is intercept of the hyper-plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f104371-6e4e-4092-a0ee-77200f99aa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.07398449000531"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.stages[0].intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ad30e-0631-411e-8132-fa05ecf5dc2b",
   "metadata": {},
   "source": [
    "### Tear down machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91d23546-a5dd-40f2-b546-256fa3bb1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop session\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edbcf9-5fb8-46a7-bf68-79e07d96e9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26683ab5-da64-40df-b69f-73a2c9ee4b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
