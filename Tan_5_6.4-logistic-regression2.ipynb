{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74184eb-254f-4d4d-b2e9-ed3adc793bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb55e15-f459-4834-8818-db06ef5ea52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/28 19:59:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/28 19:59:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=SparkConf())\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911fdd0-fb9e-4e8c-b3db-6140981ee33e",
   "metadata": {},
   "source": [
    "# Logistic Regression with pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1a489-d19d-43a4-9961-03f85e290e8e",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7fc664-918e-4ccf-9484-27d946d00e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "|age|        job|marital|education|default|balance|housing|loan| contact|duration|campaign|pdays|previous|  y|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular|      79|       1|   -1|       0| no|\n",
      "| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular|     220|       1|  339|       4| no|\n",
      "| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular|     185|       1|  330|       1| no|\n",
      "| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|     199|       4|   -1|       0| no|\n",
      "| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|     226|       1|   -1|       0| no|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/SparkData/bank.csv', header=True, inferSchema=True, sep=\";\")\n",
    "df.drop('day', 'month', 'poutcome').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7741228d-e7be-450e-8e24-6b3939ac67a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcea661-9ce6-4c3b-8894-6369b8262a4b",
   "metadata": {},
   "source": [
    "## Deal with categorical data and Convert the data to dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4c3309-2b16-433f-9ec1-15550edccf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "num_cols = ['balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "labelCol = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b40577-2833-48d4-8c0f-972234878019",
   "metadata": {},
   "source": [
    "## Process categorical columns\n",
    "The following code does three things with pipeline:\n",
    "* **`StringIndexer`** all categorical columns\n",
    "* **`OneHotEncoder`** all categorical index columns\n",
    "* **`VectorAssembler`** all feature columns into one vector column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536ff97-0c9e-4bf1-a4c5-0bcb37d9cc93",
   "metadata": {},
   "source": [
    "## Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b83ac0c-1fde-4c4c-ad6b-23130cbe7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf551861-f0b9-4039-a20b-7f67d6e4cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "categorical_columns = cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4c5fbc-1740-43ce-9d53-0b3486a6261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical columns into numerical indices\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80cd8608-153f-4254-afd9-9a44a1fdf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert indexed categorical features into one-hot encoded vectors\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), \\\n",
    "                            outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4101f9a0-ce8b-4e77-a69b-4938baab91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine feature columns into a single feature vector\n",
    "assembler = VectorAssembler(inputCols = [encoder.getOutputCol() for encoder in encoders] + num_cols, \\\n",
    "                            outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70dd7f57-32b0-41fe-9b76-e80553a7bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 19:59:36 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                 |label|\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|(29,[8,11,15,16,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1787.0,79.0,1.0,-1.0])                |no   |\n",
      "|(29,[4,11,13,16,17,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4789.0,220.0,1.0,339.0,4.0])       |no   |\n",
      "|(29,[0,12,14,16,17,18,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1350.0,185.0,1.0,330.0,1.0])|no   |\n",
      "|(29,[0,11,14,16,17,20,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1476.0,199.0,4.0,-1.0])               |no   |\n",
      "|(29,[1,11,13,16,17,18,20,21,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,226.0,1.0,-1.0])                  |no   |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = indexers + encoders + [assembler])\n",
    "model = pipeline.fit(df)                               # train the pipeline on the dataset df\n",
    "data = model.transform(df)                             # apply the pipeline to the df and tranforming\n",
    "data = data.withColumn(\"label\", col(labelCol))         # create label column\n",
    "data = data.select(\"features\", \"label\")\n",
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c2f5b-4aa2-4031-bb1d-61bb31a41d28",
   "metadata": {},
   "source": [
    "## We need to deal with label, which is string, yes or no, need to make them numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82470959-e4bc-4970-980e-645d711af4d4",
   "metadata": {},
   "source": [
    "## Build StringIndexer stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e650bdcd-9895-4ff1-b950-12c8e971cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|label|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(29,[8,11,15,16,1...|   no|         0.0|\n",
      "|(29,[4,11,13,16,1...|   no|         0.0|\n",
      "|(29,[0,12,14,16,1...|   no|         0.0|\n",
      "|(29,[0,11,14,16,1...|   no|         0.0|\n",
      "|(29,[1,11,13,16,1...|   no|         0.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol = \"label\", outputCol = \"indexedLabel\").fit(data)\n",
    "data = labelIndexer.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0c2a18-4dc2-4403-9172-6f072467f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# automatically identify categorical features, and index them.\n",
    "# set maxCategories so features with >4 distinct values are treated as continuous.\n",
    "# update metadata accordingly.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", \\\n",
    "                               maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50de0742-8360-40bf-afb0-0434d36fe47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+--------------------+\n",
      "|            features|label|indexedLabel|     indexedFeatures|\n",
      "+--------------------+-----+------------+--------------------+\n",
      "|(29,[8,11,15,16,1...|   no|         0.0|(29,[8,11,15,16,1...|\n",
      "|(29,[4,11,13,16,1...|   no|         0.0|(29,[4,11,13,16,1...|\n",
      "|(29,[0,12,14,16,1...|   no|         0.0|(29,[0,12,14,16,1...|\n",
      "|(29,[0,11,14,16,1...|   no|         0.0|(29,[0,11,14,16,1...|\n",
      "|(29,[1,11,13,16,1...|   no|         0.0|(29,[1,11,13,16,1...|\n",
      "+--------------------+-----+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = featureIndexer.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a781c5-a992-45cb-a46b-2519319c23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data to training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ca45f83-4e12-427f-be41-959b27e7fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                         |label|indexedLabel|indexedFeatures                                                                                  |\n",
      "+-------------------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-588.0,81.0,4.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-588.0,81.0,4.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,-1.0])  |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,-1.0])  |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1007.0,240.0,2.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1007.0,240.0,2.0,-1.0])|\n",
      "+-------------------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                        |label|indexedLabel|indexedFeatures                                                                                 |\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-105.0,60.0,2.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-105.0,60.0,2.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,466.0,164.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,466.0,164.0,1.0,-1.0])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,644.0,54.0,2.0,-1.0]) |no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,644.0,54.0,2.0,-1.0]) |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,725.0,266.0,1.0,-1.0])|no   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,725.0,266.0,1.0,-1.0])|\n",
      "+------------------------------------------------------------------------------------------------+-----+------------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test sets(40% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "trainingData.show(5, False)\n",
    "testData.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa9f70-6e3c-490c-9236-014fe1b81a01",
   "metadata": {},
   "source": [
    "## Build cross-validation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d63f46-5d91-48c5-ac94-b6db2add8b2c",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc226f3-aa89-42ae-808e-7bbe9b9269b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(featuresCol=\"indexedFeatures\", labelCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a7759-e94b-4e0f-a89a-7090915eb170",
   "metadata": {},
   "source": [
    "### Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "818e4245-5815-4887-8076-e658c78fd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert indexed labels back to original labels.\n",
    "from pyspark.ml.feature import IndexToString\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", \\\n",
    "                                labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c3ea72f-0a2d-4e31-a050-47c64827241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[logr, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b70b2b8-f1ba-4eb4-ba46-574c0ddbb521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 19:59:58 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "# train model, also runs the indexers\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54248df7-a10e-46de-ad78-2c41536cf740",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be630811-fa52-4ad8-81a1-0c7ed037c595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+--------------------+\n",
      "|            features|label|predictedLabel|       rawPrediction|\n",
      "+--------------------+-----+--------------+--------------------+\n",
      "|(29,[0,11,13,16,1...|   no|            no|[3.64520239761018...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[0.66304084695874...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[3.15871192900358...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[3.64482052432358...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[2.75409657899604...|\n",
      "+--------------------+-----+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions.\n",
    "predictions = model.transform(testData)\n",
    "# select example rows to display\n",
    "predictions.select(\"features\", \"label\", \"predictedLabel\", \"rawPrediction\").show(5)\n",
    "# predictions.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d2954-6a40-4552-b601-fc6fc84246c6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6bb8bc7-f206-4f6c-84e5-6faa32f24d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8987271721084671\n",
      "Test Error = 0.101273\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b6f55-6daf-4767-8765-22b95d094663",
   "metadata": {},
   "source": [
    "### Evaluate training model\n",
    "- Area under ROC https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "- Accuracy\n",
    "- False positive rate by label\n",
    "- True positive rate by label\n",
    "- Precision by label\n",
    "- Recall by label\n",
    "- F-measure by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7a0b174-3410-4e6d-a8ce-36eb5c11fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = model.stages[0]\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ba292e-f948-4669-8dfa-61847eb0451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|4.151100041511000...|0.003278688524590164|\n",
      "|8.302200083022001E-4|0.006557377049180328|\n",
      "|8.302200083022001E-4|0.013114754098360656|\n",
      "|8.302200083022001E-4|0.019672131147540985|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "areaUnderROC: 0.8844054740079826\n",
      "accuracy: 0.9034635224760501\n"
     ]
    }
   ],
   "source": [
    "# obtain the objective per iteration\n",
    "# objectiveHistory = trainingSummary.objectiveHistory\n",
    "# print(\"objectiveHistory:\")\n",
    "# for objectie in objectiveHistory:\n",
    "#     print(objective)\n",
    "# obtain the receiver-operating characteristic as a dataframe and areaUnderROC\n",
    "trainingSummary.roc.show(5)\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "print(f\"accuracy: {str(trainingSummary.accuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "350831fb-cba2-4367-82d2-4b5e071c080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|            features|label|indexedLabel|     indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+--------------------+-----+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.64520239761018...|[0.97454856923068...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[0.66304084695874...|[0.65994314136597...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.15871192900358...|[0.95925062697289...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.64482052432358...|[0.97453909566059...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[2.75409657899604...|[0.94014429270924...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.17988847436936...|[0.96007039090524...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.45888484754576...|[0.96949500398597...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.23421600362815...|[0.96210177647884...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.00112733401723...|[0.73128016820737...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.43923261517160...|[0.96890840676100...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.54871961588371...|[0.97204265185893...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|  yes|         1.0|(29,[0,11,13,16,1...|[0.61710623693140...|[0.64956012158557...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[2.92710580584696...|[0.94917022283989...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[3.58109660958396...|[0.97290920100777...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[4.54681735152024...|[0.98951031038555...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[4.64748581510336...|[0.99050534087523...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[0.41208736535591...|[0.60158828413242...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[4.51537690242920...|[0.98917889603110...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[4.50108064951629...|[0.98902479375204...|       0.0|            no|\n",
      "|(29,[0,11,13,16,1...|   no|         0.0|(29,[0,11,13,16,1...|[1.89840021242442...|[0.86971035409520...|       0.0|            no|\n",
      "+--------------------+-----+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "907468ec-8276-494c-ac36-c2426c733ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n",
      "label 0:0.6918032786885245\n",
      "label 1:0.021170610211706103\n"
     ]
    }
   ],
   "source": [
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i in range(len(trainingSummary.falsePositiveRateByLabel)):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.falsePositiveRateByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0620a559-8e54-416e-9b14-eb767484c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0:0.9788293897882939\n",
      "label 1:0.3081967213114754\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i in range(len(trainingSummary.truePositiveRateByLabel)):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.truePositiveRateByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "603388b0-5f9a-444c-a937-a29c06aa3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by label\n",
      "label 0:0.917866874270144\n",
      "label 1:0.6482758620689655\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by label\")\n",
    "for i in range(len(trainingSummary.precisionByLabel)):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.precisionByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0801cf09-f238-4e9e-aa42-9077b8bd201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall by label\n",
      "label 0:0.9788293897882939\n",
      "label 1:0.3081967213114754\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall by label\")\n",
    "for i in range(len(trainingSummary.recallByLabel)):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.recallByLabel[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06692ec6-ade9-4534-96be-62fd97a69473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure by label\n",
      "label 0:0.9473684210526316\n",
      "label 1:0.4177777777777778\n"
     ]
    }
   ],
   "source": [
    "print(\"F-measure by label\")\n",
    "for i in range(len(trainingSummary.fMeasureByLabel())):\n",
    "    print(\"label {}:{}\".format(i, trainingSummary.fMeasureByLabel()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c59a1e26-af7d-4138-a666-20e70ea4281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9034635224760501\n",
      "FPR: 0.6164374113762807\n",
      "TPR: 0.9034635224760501\n",
      "F-measure: 0.8878528918710434\n",
      "Precision: 0.8875701687722224\n",
      "Recall: 0.9034635224760501\n"
     ]
    }
   ],
   "source": [
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: {0}\\nFPR: {1}\\nTPR: {2}\\nF-measure: {3}\\nPrecision: {4}\\nRecall: {5}\".format\\\n",
    "      (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527447d-7fe5-41f2-b4c2-71e482e20b4d",
   "metadata": {},
   "source": [
    "### Here is the slope W amd intercept b of the line, z = w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a20d103d-fc95-4ad8-9034-1cacf270e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.5862, -0.9179, -0.5628, -0.3719, -0.6432, 0.2584, 0.0449, -0.8041, -1.2865, -0.3527, 0.2347, -0.5099, -0.3418, 0.4983, 0.7957, 0.5328, -0.7769, -0.5416, 0.9179, 0.3879, -0.7224, -2.668, -2.4764, -1.7132, 0.0, 0.0039, -0.0642, -0.0002, -0.0158])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50b66e48-0915-4cbd-847c-248e234bd14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46827825766787523"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaaf12e-71c6-455d-9bca-c2c2f8fab4df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
